{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shubhs42/DeepLearnCVBootCamp/blob/main/NLP_Assignment_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NBKn00GGP-ik"
      },
      "source": [
        "# **Assignment 2**\n",
        "## **Artificial Neural Network for Text Sentiment Classification**\n",
        "\n",
        "Text sentiment classification using neural networks (NN) involves training a model to analyze and classify the sentiment expressed in text, such as positive, negative, or neutral. Neural networks, particularly recurrent networks (RNNs) or transformers (which will be explored subsequently), can capture the sequential nature of text data, making them well-suited for this task. By embedding words into dense vectors, a feed forward neural network can learn to associate patterns in word usage with sentiment labels. During training, the model adjusts its weights to minimize error, enabling it to generalize to unseen text, ultimately predicting sentiment with high accuracy."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tg5A1A2YP-im"
      },
      "source": [
        "===================================================================================================="
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A8gsjW74P-in"
      },
      "source": [
        "<style>\n",
        "blue {\n",
        "  color: skyblue;\n",
        "}\n",
        "\n",
        "green {\n",
        "  color: lightgreen;\n",
        "}\n",
        "</style>\n",
        "\n",
        "### **Step - 1**\n",
        "This code imports necessary libraries for text preprocessing, model building, and evaluation.\n",
        "1)  It uses <blue>**pandas**</blue> for <green>**data handling**</green>.\n",
        "2) <blue>**Matplotlib**</blue> for <green>**plotting**</green>.\n",
        "3) <blue>**NLTK**</blue> for <green>**tokenizing**</green> and <green>**stemming**</green> text.\n",
        "4) It includes <blue>**scikit-learn**</blue> for <green>**splitting data**</green> and <green>**evaluation (classification_report)**</green>.\n",
        "5) <blue>**Torch**</blue> is used to <green>**define**</green>, <green>**train**</green>, and <green>**optimize**</green> neural networks.\n",
        "6) <blue>**gensim**</blue> is used for <green>**dictionary creation**</green> and <green>**token mapping**</green>, helping to convert text into numerical format for model training."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gensim"
      ],
      "metadata": {
        "id": "upUc5SBoi8XF",
        "outputId": "0ad48087-dba6-412e-873d-621640b9fec5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gensim\n",
            "  Downloading gensim-4.4.0-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (8.4 kB)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.12/dist-packages (from gensim) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from gensim) (1.16.2)\n",
            "Requirement already satisfied: smart_open>=1.8.1 in /usr/local/lib/python3.12/dist-packages (from gensim) (7.4.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.12/dist-packages (from smart_open>=1.8.1->gensim) (2.0.0)\n",
            "Downloading gensim-4.4.0-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (27.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.9/27.9 MB\u001b[0m \u001b[31m71.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: gensim\n",
            "Successfully installed gensim-4.4.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "jsu0AUg8P-in"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import PorterStemmer\n",
        "from sklearn.model_selection import train_test_split\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torch\n",
        "from gensim import corpora\n",
        "from sklearn.metrics import classification_report"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZCWSFo-bP-io"
      },
      "source": [
        "<style>\n",
        "blue {\n",
        "  color: skyblue;\n",
        "}\n",
        "\n",
        "green {\n",
        "  color: lightgreen;\n",
        "}\n",
        "</style>\n",
        "\n",
        "### **Step - 2**\n",
        "This code <green>**loads**</green> the <blue>**\"yelp_reviews_subset_2.csv\"**</blue> dataset downloaded from the Notion page."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "D4xgi7ZNP-io",
        "outputId": "5fec0a8a-22e2-4ed0-d8ff-81d782530784",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     Unnamed: 0                                               Text  Labels\n",
              "0             0  My expectations for McDonalds are t rarely hig...       0\n",
              "1             1  I've tried to give this McDonalds a chance but...       0\n",
              "2             2  This McDonald's is so bad it's amazing.  \\n\\nO...       0\n",
              "3             3  We had the worst possible experience at the Ea...       0\n",
              "4             4  They burned my fish and they burned it bad.  O...       2\n",
              "..          ...                                                ...     ...\n",
              "495         495  This place is PHENOMENAL.\\nI got my bunny here...       4\n",
              "496         496  This is a bizarre CVS, the kind you would only...       1\n",
              "497         497  I go to this CVS all the time, since I work in...       1\n",
              "498         498  Never again. Let me repeat, never again. \\n\\nT...       0\n",
              "499         499  The times I've been here, its been an OK exper...       1\n",
              "\n",
              "[500 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a7234ccd-5aa2-4704-9346-d5fe85c04983\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Text</th>\n",
              "      <th>Labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>My expectations for McDonalds are t rarely hig...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>I've tried to give this McDonalds a chance but...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>This McDonald's is so bad it's amazing.  \\n\\nO...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>We had the worst possible experience at the Ea...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>They burned my fish and they burned it bad.  O...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>495</th>\n",
              "      <td>495</td>\n",
              "      <td>This place is PHENOMENAL.\\nI got my bunny here...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>496</th>\n",
              "      <td>496</td>\n",
              "      <td>This is a bizarre CVS, the kind you would only...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>497</th>\n",
              "      <td>497</td>\n",
              "      <td>I go to this CVS all the time, since I work in...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>498</th>\n",
              "      <td>498</td>\n",
              "      <td>Never again. Let me repeat, never again. \\n\\nT...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>499</th>\n",
              "      <td>499</td>\n",
              "      <td>The times I've been here, its been an OK exper...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>500 rows × 3 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a7234ccd-5aa2-4704-9346-d5fe85c04983')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-a7234ccd-5aa2-4704-9346-d5fe85c04983 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-a7234ccd-5aa2-4704-9346-d5fe85c04983');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-c906c15e-e249-4a6d-b0d5-3c34c39c40a2\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-c906c15e-e249-4a6d-b0d5-3c34c39c40a2')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-c906c15e-e249-4a6d-b0d5-3c34c39c40a2 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_f99e85fe-2471-40f4-9244-1b482467c2f5\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_f99e85fe-2471-40f4-9244-1b482467c2f5 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 500,\n  \"fields\": [\n    {\n      \"column\": \"Unnamed: 0\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 144,\n        \"min\": 0,\n        \"max\": 499,\n        \"num_unique_values\": 500,\n        \"samples\": [\n          361,\n          73,\n          374\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 500,\n        \"samples\": [\n          \"Meh. I've ordered from here twice and not really been enthusiastic about the results either time. Keep in mind that I haven't had pizza from this place yet!\\\\n\\\\nTheir steak hoagie is middling-good; nothing to write home about, but a pretty good example of the standard Pittsburgh pizza place steak hoagie.\\\\n\\\\nThe seafood calzone is another story. Something in it was so bitter I couldn't quite eat it; I'm wondering if it was the garlic or perhaps a leftover burnt taste from the oven. Whatever it was, it was gross. The shrimp weren't that good either, suffering as they did from that certain \\\\\\\"I taste like iodine\\\\\\\" flavor.\\\\n\\\\nThe advantage to R&B is that they're open reasonably late, given the location, but the phone service is rather surly and it always takes them an hour plus to deliver. Which would be OK if I didn't live a block away (normally I'd just walk and pick it up, but just for you, Yelpers, I subject myself to the vagaries of sitting on my rear end on the couch waiting for my food to arrive).\",\n          \"Before today I probably would have given this place three stars based mostly on their beer selection; however, today the service was terrible. We waited two hours for a pizza sub, French onion soup, fries, and buffalo chicken tenders. About an hour and a half in we finally got the small pizza sub and the wrongly made buffalo chicken tenders (ie, no hot sauce). We were told by the waitress that she realized it was wrong, but decided to still bring it out to see if my gf would eat it. She sent it back. By a half hour later, we still had not received the buffalo chicken tenders, nor the French onion soup (which should have been mostly made already), and no fries.  We were told the chef was new, but no effort was made really to make the situation better. No quick and easy app or beers on the house. To boot, the beer was pretty expensive. I will probably give the place another chance based on their beer selection, but it won't be for a while. The food has always been average at best, and the pizza sub was no different. We ended up leaving after two hours without receiving 75% of our order.\",\n          \"Horrifying.  This place should be ashamed of itself.  DO NOT STAY HERE.  Beyond dirty, just absolutely rank.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Labels\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 0,\n        \"max\": 4,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          2,\n          3,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "# TODO: Download and Load the \"yelp_reviews_subset_2.csv\" dataset uploaded on the notion page using pandas\n",
        "url='https://raw.githubusercontent.com/shubhs42/DeepLearnCVBootCamp/refs/heads/main/NLP_AS_2_yelp_reviews_subset_2.csv'\n",
        "df = pd.read_csv(url) # Replace None with the correct code\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N2hQ8kRuP-io"
      },
      "source": [
        "<style>\n",
        "blue {\n",
        "  color: skyblue;\n",
        "}\n",
        "\n",
        "green {\n",
        "  color: lightgreen;\n",
        "}\n",
        "</style>\n",
        "\n",
        "### **Step - 3**\n",
        "This code maps review star ratings to sentiment categories and visualizes the sentiment distribution.\n",
        "\n",
        "1) The function <blue>**map_sentiment**</blue> converts star ratings into <green>**three categories**</green>: negative (-1 for stars ≤ 2), neutral (0 for 3 stars), and positive (1 for stars ≥ 4).\n",
        "2) It applies this function to the <blue>**Labels**</blue> column in df, creating a new column <blue>**sentiment**</blue>.\n",
        "3) The code then plots a bar chart showing the <green>**distribution of the sentiments**</green> using matplotlib and pandas, labeling the x-axis as \"Sentiment\" and the y-axis as \"No. of rows in df\"."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "93d-J5GeP-ip"
      },
      "outputs": [],
      "source": [
        "def map_sentiment(stars_received):\n",
        "    if stars_received <= 2:\n",
        "        return -1\n",
        "    elif stars_received == 3:\n",
        "        return 0\n",
        "    else:\n",
        "        return 1\n",
        "\n",
        "\n",
        "# Mapping stars to sentiment into three categories\n",
        "df['sentiment'] = [ map_sentiment(x) for x in df['Labels']]\n",
        "# Plotting the sentiment distribution\n",
        "plt.figure()\n",
        "pd.value_counts(df['sentiment']).plot.bar(title=\"Sentiment distribution in df\")\n",
        "plt.xlabel(\"Sentiment\")\n",
        "plt.ylabel(\"No. of rows in df\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9JnekDAKP-ip"
      },
      "source": [
        "<style>\n",
        "blue {\n",
        "  color: skyblue;\n",
        "}\n",
        "\n",
        "green {\n",
        "  color: lightgreen;\n",
        "}\n",
        "</style>\n",
        "\n",
        "### **Step - 4**\n",
        "This code tokenizes text and stems the words using NLTK tools.\n",
        "\n",
        "1) It <green>**tokenizes**</green> each sentence in the dataframe <blue>**df['tokenized_text']**</blue> using <blue>**word_tokenize**</blue> from NLTK, applying <green>**list comprehension**</green> to store the tokens as a list.\n",
        "2) Next, it uses the <blue>**Porter Stemmer**</blue> to <green>**stem**</green> each token in <blue>**df['tokenized_text']**</blue>, storing the stemmed words in <blue>**df['stemmed_tokens']**</blue> using <green>**list comprehension**</green>.\n",
        "\n",
        "Both processes are applied to make the text more suitable for sentiment classification by reducing it to basic word forms."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WHPkH5WEP-iq"
      },
      "outputs": [],
      "source": [
        "# TODO: Tokenize each sentence into word tokens and store them as a list in the dataframe\n",
        "# Use List Comprehension\n",
        "df['tokenized_text'] = None # Replace None with the correct code\n",
        "print(df['tokenized_text'].head(10))\n",
        "\n",
        "ps = PorterStemmer()\n",
        "# TODO: Use the Porter Stemmer to find stem words of each word for all the words in df[\"tokenized_text\"]\n",
        "# Hint: Use List Comprehension\n",
        "df['stemmed_tokens'] = None # Replace None with the correct code\n",
        "df['stemmed_tokens'].head(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vRWJ81tyP-iq"
      },
      "source": [
        "<style>\n",
        "blue {\n",
        "  color: skyblue;\n",
        "}\n",
        "\n",
        "green {\n",
        "  color: lightgreen;\n",
        "}\n",
        "</style>\n",
        "\n",
        "### **Step - 5**\n",
        "This code splits the dataset into training and testing sets for model evaluation.\n",
        "<blue>**split_train_test**</blue> function uses <blue>**train_test_split**</blue> from scikit-learn to divide the dataset into <green>**training (70%)**</green> and <green>**testing (30%)**</green> sets based on the tokenized_text, stemmed_tokens, and other columns."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o_NPDenGP-iq"
      },
      "outputs": [],
      "source": [
        "# Train Test Split Function\n",
        "def split_train_test(df, test_size=0.3, shuffle_state=True):\n",
        "    X_train, X_test, Y_train, Y_test = train_test_split(df[[\"Text\", \"Labels\", \"tokenized_text\", \"stemmed_tokens\"]],\n",
        "                                                        df['sentiment'],\n",
        "                                                        shuffle=shuffle_state,\n",
        "                                                        test_size=test_size,\n",
        "                                                        random_state=15)\n",
        "    print(\"Value counts for Train sentiments\")\n",
        "    print(Y_train.value_counts())\n",
        "    print(\"Value counts for Test sentiments\")\n",
        "    print(Y_test.value_counts())\n",
        "    print(type(X_train))\n",
        "    print(type(Y_train))\n",
        "    X_train = X_train.reset_index()\n",
        "    X_test = X_test.reset_index()\n",
        "    Y_train = Y_train.to_frame()\n",
        "    Y_train = Y_train.reset_index()\n",
        "    Y_test = Y_test.to_frame()\n",
        "    Y_test = Y_test.reset_index()\n",
        "    print(X_train.head())\n",
        "    return X_train, X_test, Y_train, Y_test\n",
        "\n",
        "# Call the train_test_split\n",
        "X_train, X_test, Y_train, Y_test = split_train_test(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kGRjZU7XP-ir"
      },
      "source": [
        "<style>\n",
        "blue {\n",
        "  color: skyblue;\n",
        "}\n",
        "\n",
        "green {\n",
        "  color: lightgreen;\n",
        "}\n",
        "</style>\n",
        "\n",
        "### **Step - 6**\n",
        "This code sets the <blue>**device**</blue> for running the model, either using <green>**GPU**</green> if available or falling back to <green>**CPU**</green>.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n7kZXoAlP-ir"
      },
      "outputs": [],
      "source": [
        "# TODO: Set device (GPU if available, else CPU)\n",
        "device = None # Replace None with the correct code\n",
        "print(\"Device available for running: \")\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x2835pU8P-ir"
      },
      "source": [
        "<style>\n",
        "blue {\n",
        "  color: skyblue;\n",
        "}\n",
        "\n",
        "green {\n",
        "  color: lightgreen;\n",
        "}\n",
        "</style>\n",
        "\n",
        "### **Step - 7**\n",
        "This code defines a Feedforward Neural Network model with three fully connected layers using PyTorch.\n",
        "\n",
        "1) <blue>**fc1**</blue>: First fully connected layer that takes the <green>**input dimension (input_dim)**</green> and maps it to a <green>**hidden dimension (hidden_dim)**</green>.\n",
        "2) <blue>**fc2**</blue>: Second fully connected layer that maps the <green>**hidden dimension (hidden_dim)**</green> to another <green>**hidden dimension (hidden_dim)**</green>.\n",
        "3) <blue>**fc3**</blue>: Final layer that maps the <green>**hidden dimension**</green> to the <green>**output dimension (output_dim)**</green>, which corresponds to the sentiment classification."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gsMNtsFjP-ir"
      },
      "outputs": [],
      "source": [
        "class FeedforwardNeuralNetModel(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
        "        super(FeedforwardNeuralNetModel, self).__init__()\n",
        "\n",
        "        # TODO: Add an fc1 layer as described below\n",
        "        # Linear function 1: vocab_size --> hiiden_dim\n",
        "        self.fc1 = None # Replace None with the correct code\n",
        "\n",
        "        # Non-linearity 1\n",
        "        self.relu1 = nn.ReLU()\n",
        "\n",
        "        # TODO: Add an fc2 layer as described below\n",
        "        # Linear function 2: hidden_dim --> hidden_dim\n",
        "        self.fc2 = None # Replace None with the correct code\n",
        "\n",
        "        # Non-linearity 2\n",
        "        self.relu2 = nn.ReLU()\n",
        "\n",
        "        # TODO: Add an fc3 layer as described below\n",
        "        # Linear function 3 (readout): hidden_dim --> output_dim\n",
        "        self.fc3 = None  # Replace None with the correct code\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        # TODO: Forward pass through fully connected layer 1\n",
        "        out = None # Replace None with the correct code\n",
        "\n",
        "        # Non-linearity 1\n",
        "        out = self.relu1(out)\n",
        "\n",
        "        # TODO: Forward pass through fully connected layer 2\n",
        "        out = None # Replace None with the correct code\n",
        "\n",
        "        # Non-linearity 2\n",
        "        out = self.relu2(out)\n",
        "\n",
        "        # TODO: Forward pass through fully connected layer 3\n",
        "        out = None # Replace None with the correct code\n",
        "\n",
        "        return F.softmax(out, dim=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OsTy4gvWP-ir"
      },
      "source": [
        "<style>\n",
        "blue {\n",
        "  color: skyblue;\n",
        "}\n",
        "\n",
        "green {\n",
        "  color: lightgreen;\n",
        "}\n",
        "</style>\n",
        "\n",
        "### **Step - 8**\n",
        "This code defines a function to create a dictionary of tokens from a DataFrame using Gensim's corpora.Dictionary.\n",
        "\n",
        "1) <blue>**make_dict**</blue> generates a <green>**token dictionary**</green> from the <blue>**stemmed_tokens**</blue> column in the DataFrame.\n",
        "2) If <blue>**padding=True**</blue>, it adds a <green>**padding token ('pad')**</green> to the dictionary, which is useful for models that require fixed input sizes.\n",
        "3) If <blue>**padding=False**</blue>, the dictionary is created directly from the tokenized text <green>**without adding a padding token**</green>.\n",
        "4) The <blue>**review_dict**</blue> variable stores the dictionary, and in this case, it is created <green>**without padding**</green> by calling the function with <blue>**padding=False**</blue>.\n",
        "\n",
        "This process is helpful for converting text tokens into numerical indices that can be used as input for machine learning models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A-JTlz0tP-is"
      },
      "outputs": [],
      "source": [
        "# Function to return the dictionary either with padding word or without padding\n",
        "def make_dict(top_data_df_small, padding=True):\n",
        "    if padding:\n",
        "        print(\"Dictionary with padded token added\")\n",
        "        review_dict = corpora.Dictionary([['pad']])\n",
        "        review_dict.add_documents(top_data_df_small['stemmed_tokens'])\n",
        "    else:\n",
        "        print(\"Dictionary without padding\")\n",
        "        review_dict = corpora.Dictionary(top_data_df_small['stemmed_tokens'])\n",
        "    return review_dict\n",
        "\n",
        "# Make the dictionary without padding for the basic models\n",
        "review_dict = make_dict(df, padding=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lbKQBL6mP-is"
      },
      "source": [
        "<style>\n",
        "blue {\n",
        "  color: skyblue;\n",
        "}\n",
        "\n",
        "green {\n",
        "  color: lightgreen;\n",
        "}\n",
        "</style>\n",
        "\n",
        "### **Step - 9**\n",
        "This code creates functions to generate input and target tensors for the neural network.\n",
        "\n",
        "1) <blue>**make_bow_vector**</blue>: This function creates a <green>**bag-of-words (BOW)**</green> vector from a tokenized sentence.\n",
        "\n",
        "2) It initializes a <blue>**zero vector**</blue> of size <blue>**VOCAB_SIZE (30,056)**</blue>, where <green>**each index**</green> represents a word from the vocabulary.\n",
        "\n",
        "3) <blue>**make_target**</blue>: This function converts a <green>**sentiment label (-1, 0, or 1)**</green> into a tensor for the output.\n",
        "\n",
        "4) <blue>**Negative sentiment (-1)**</blue> maps to <green>**0**</green>, <blue>**neutral sentiment (0)**</blue> maps to <green>**1**</green>, and <blue>**positive sentiment (1)**</blue> maps to <green>**2**</green>."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SzRayQh_P-is"
      },
      "outputs": [],
      "source": [
        "VOCAB_SIZE = 30056\n",
        "NUM_LABELS = 3\n",
        "\n",
        "# Function to make bow vector to be used as input to network\n",
        "def make_bow_vector(review_dict, sentence):\n",
        "    vec = torch.zeros(VOCAB_SIZE, dtype=torch.float64, device=device)\n",
        "    for word in sentence:\n",
        "        vec[review_dict.token2id[word]] += 1\n",
        "    return vec.view(1, -1).float()\n",
        "\n",
        "# Function to get the output tensor\n",
        "def make_target(label):\n",
        "    if label == -1:\n",
        "        return torch.tensor([0], dtype=torch.long, device=device)\n",
        "    elif label == 0:\n",
        "        return torch.tensor([1], dtype=torch.long, device=device)\n",
        "    else:\n",
        "        return torch.tensor([2], dtype=torch.long, device=device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t_OU0gZdP-it"
      },
      "source": [
        "<style>\n",
        "blue {\n",
        "  color: skyblue;\n",
        "}\n",
        "\n",
        "green {\n",
        "  color: lightgreen;\n",
        "}\n",
        "</style>\n",
        "\n",
        "### **Step - 10**\n",
        "1) <blue>**Model Initialization**</blue>: The <green>**Feedforward Neural Network**</green> is instantiated with input_dim, hidden_dim, and output_dim.\n",
        "2) <blue>**Device Transfer**</blue>: The model is moved to the <green>**GPU**</green> or <green>**CPU**</green> as specified earlier.\n",
        "3) <blue>**Loss Function**</blue>: The loss function is set to <green>**CrossEntropyLoss**</green>, suitable for multi-class classification.\n",
        "4) <blue>**Optimizer**</blue>: The optimizer is <green>**SGD (Stochastic Gradient Descent)**</green> with a <green>**learning rate**</green> of <green>**1e-3**</green>."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ERQt5edLP-it"
      },
      "outputs": [],
      "source": [
        "VOCAB_SIZE = len(review_dict)\n",
        "\n",
        "input_dim = VOCAB_SIZE\n",
        "hidden_dim = 500\n",
        "output_dim = 3\n",
        "num_epochs = 100\n",
        "\n",
        "# TODO: Call the FeedForwardNeuralNetwork Class object with appropriate arguements\n",
        "ff_nn_bow_model = None # Replace None with the correct code\n",
        "\n",
        "# TODO: Move the model to device\n",
        "ff_nn_bow_model = None # Replace None with the correct code\n",
        "\n",
        "# TODO: Define the loss function as Cross Entropy Loss\n",
        "loss_function = None # Replace None with the correct code\n",
        "\n",
        "# TODO: Define a Stochastic Gradient Descent Optimizer with learning rate of 1e-3\n",
        "optimizer = None # Replace None with the correct code"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z9rIhSF0P-it"
      },
      "source": [
        "<style>\n",
        "blue {\n",
        "  color: skyblue;\n",
        "}\n",
        "\n",
        "green {\n",
        "  color: lightgreen;\n",
        "}\n",
        "</style>\n",
        "\n",
        "### **Step - 11**\n",
        "1) <blue>**Bag-of-Words Vector**</blue>: The <green>**make_bow_vector**</green> function is used to create a BOW vector from the stemmed tokens.\n",
        "2) <blue>**Forward Pass**</blue>: The <green>**BOW vector**</green> is passed through the <green>**feedforward neural network**</green> to get the output probabilities.\n",
        "3) <blue>**Loss Calculation**</blue>: The <green>**CrossEntropyLoss**</green> is computed between the output probabilities and the target label.\n",
        "4) <blue>**Gradient Update**</blue>: <green>**Gradients**</green> are calculated and the parameters are updated using backpropagation and <green>**optimizer.step()**</green>.\n",
        "5) <blue>**Loss Logging**</blue>: The <green>**average loss per epoch**</green> is written to the loss file for tracking training progress."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6GvaOfT_P-it"
      },
      "outputs": [],
      "source": [
        "# Open the file for writing loss\n",
        "ffnn_loss_file_name = 'ffnn_bow_class_big_loss_500_epoch_100_less_lr.csv'\n",
        "f = open(ffnn_loss_file_name,'w')\n",
        "f.write('iter, loss')\n",
        "f.write('\\n')\n",
        "losses = []\n",
        "iter = 0\n",
        "# Start training\n",
        "for epoch in range(num_epochs):\n",
        "    if (epoch+1) % 25 == 0:\n",
        "        print(\"Epoch completed: \" + str(epoch+1))\n",
        "    train_loss = 0\n",
        "    for index, row in X_train.iterrows():\n",
        "        # Clearing the accumulated gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # TODO: Make the bag of words vector for stemmed tokens\n",
        "        bow_vec = None # Replace None with the correct code\n",
        "\n",
        "        # TODO: Forward pass to get output\n",
        "        probs = None # Replace None with the correct code\n",
        "\n",
        "        # Get the target label\n",
        "        target = make_target(Y_train['sentiment'][index])\n",
        "\n",
        "        # TODO: Calculate Loss: softmax --> cross entropy loss\n",
        "        loss = None # Replace None with the correct code\n",
        "\n",
        "        # Accumulating the loss over time\n",
        "        train_loss += loss.item()\n",
        "\n",
        "        # Getting gradients w.r.t. parameters\n",
        "        loss.backward()\n",
        "\n",
        "        # Updating parameters\n",
        "        optimizer.step()\n",
        "    f.write(str((epoch+1)) + \",\" + str(train_loss / len(X_train)))\n",
        "    f.write('\\n')\n",
        "    train_loss = 0\n",
        "\n",
        "f.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mWZfg2QgP-it"
      },
      "source": [
        "<style>\n",
        "blue {\n",
        "  color: skyblue;\n",
        "}\n",
        "\n",
        "green {\n",
        "  color: lightgreen;\n",
        "}\n",
        "</style>\n",
        "\n",
        "### **Step - 12**\n",
        "This code evaluates the performance of the trained feedforward neural network on the test dataset and visualizes the loss during training.\n",
        "\n",
        "1) <blue>**Prediction Loop**</blue>: It iterates through the test set X_test without tracking gradients <green>**(using torch.no_grad())**</green> for efficient inference. For each test sample, it generates a <green>**BOW vector**</green> and passes it through the model to obtain predicted probabilities.\n",
        "\n",
        "2) <blue>**Classification Report**</blue>: The <green>**classification_report**</green> from <green>**sklearn.metrics**</green> is printed to evaluate the model's performance, displaying precision, recall, F1-score, and support for each class.\n",
        "\n",
        "3) <blue>**Loss DataFrame**</blue>: The loss data saved in <green>**ffnn_loss_file_name**</green> is read into a DataFrame.\n",
        "\n",
        "4) <blue>**Loss Plotting**</blue>: The loss is plotted using pandas and saved as a JPEG file named <green>**\"ffnn_bow_loss_500_padding_100_epochs_less_lr.jpg\"**</green>."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JOjQ9wo2P-iu"
      },
      "outputs": [],
      "source": [
        "bow_ff_nn_predictions = []\n",
        "original_lables_ff_bow = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for index, row in X_test.iterrows():\n",
        "        bow_vec = make_bow_vector(review_dict, row['stemmed_tokens'])\n",
        "        probs = ff_nn_bow_model(bow_vec)\n",
        "        bow_ff_nn_predictions.append(torch.argmax(probs, dim=1).cpu().numpy()[0])\n",
        "        original_lables_ff_bow.append(make_target(Y_test['sentiment'][index]).cpu().numpy()[0])\n",
        "\n",
        "print(classification_report(original_lables_ff_bow,bow_ff_nn_predictions))\n",
        "ffnn_loss_df = pd.read_csv(ffnn_loss_file_name)\n",
        "print(len(ffnn_loss_df))\n",
        "print(ffnn_loss_df.columns)\n",
        "ffnn_plt_500_padding_100_epochs = ffnn_loss_df[' loss'].plot()\n",
        "fig = ffnn_plt_500_padding_100_epochs.get_figure()\n",
        "fig.savefig(\"ffnn_bow_loss_500_padding_100_epochs_less_lr.jpg\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Advanced Steps (Optional for people targeting basic level)"
      ],
      "metadata": {
        "id": "IaU71TxWRSUS"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7151e5f5"
      },
      "source": [
        "### **Step - 13**\n",
        "This code defines and trains a Feedforward Neural Network model with Dropout for regularization.\n",
        "\n",
        "1. **Model Initialization**: The **Feedforward Neural Network** is instantiated with input_dim, hidden_dim, output_dim, and a dropout rate.\n",
        "2. **Device Transfer**: The model is moved to the **GPU** or **CPU**.\n",
        "3. **Loss Function**: The loss function is set to **CrossEntropyLoss**.\n",
        "4. **Optimizer**: The optimizer is **SGD (Stochastic Gradient Descent)** with a **learning rate** of **1e-3**.\n",
        "5. **Training Loop**: The model is trained on the training data, calculating and minimizing the loss using backpropagation and the optimizer.\n",
        "6. **Loss Logging**: The average loss per epoch is written to a new loss file for tracking training progress."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the Feedforward Neural Network model with dropout\n",
        "# TODO: Create a model instance with the given input, hidden, and output dimensions\n",
        "ff_nn_bow_model_dropout = None  # Replace None with model initialization (include dropout_rate parameter)\n",
        "ff_nn_bow_model_dropout.to(device)\n",
        "\n",
        "# TODO: Define loss function and optimizer\n",
        "loss_function_dropout = None  # Replace None with appropriate loss function\n",
        "optimizer_dropout = None  # Replace None with optimizer\n",
        "\n",
        "# TODO: Prepare to record training loss\n",
        "ffnn_loss_file_name_dropout = 'ffnn_bow_class_big_loss_500_epoch_100_less_lr_dropout.csv'\n",
        "f_dropout = open(ffnn_loss_file_name_dropout, 'w')\n",
        "f_dropout.write('iter, loss\\n')\n",
        "losses_dropout = []\n",
        "iter_dropout = 0\n",
        "\n",
        "# Train the model\n",
        "ff_nn_bow_model_dropout.train()\n",
        "for epoch in range(num_epochs):\n",
        "    if (epoch + 1) % 25 == 0:\n",
        "        print(f\"Epoch completed: {epoch + 1}\")\n",
        "\n",
        "    train_loss_dropout = 0\n",
        "\n",
        "    # TODO: Iterate through training samples\n",
        "    for index, row in X_train.iterrows():\n",
        "        optimizer_dropout.zero_grad()\n",
        "\n",
        "        # TODO: Create bag-of-words input vector and target\n",
        "        bow_vec = None  # Replace None with code to create BoW vector from review_dict and tokens (call previous functions defined)\n",
        "        probs = None  # Replace None with forward pass through the model\n",
        "        target = None  # Replace None with code to create target tensor\n",
        "\n",
        "        # TODO: Compute loss\n",
        "        loss = None  # Replace None with loss computation\n",
        "        train_loss_dropout += loss.item()\n",
        "\n",
        "        # Backward pass and optimization\n",
        "        loss.backward()\n",
        "        optimizer_dropout.step()\n",
        "\n",
        "    # Log average loss for the epoch\n",
        "    f_dropout.write(f\"{epoch + 1},{train_loss_dropout / len(X_train)}\\n\")\n",
        "    train_loss_dropout = 0\n",
        "\n",
        "f_dropout.close()\n"
      ],
      "metadata": {
        "id": "rIDC4ZDxRhm9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fc14a55e"
      },
      "source": [
        "### **Step - 14**\n",
        "This code evaluates the performance of the trained feedforward neural network with Dropout on the test dataset and visualizes the loss during training, comparing it with the model without dropout.\n",
        "\n",
        "1. **Prediction Loop**: It iterates through the test set X_test with the dropout model.\n",
        "2. **Classification Report**: The **classification_report** from **sklearn.metrics** is printed to evaluate the model's performance with dropout.\n",
        "3. **Loss DataFrame**: The loss data saved for both models is read into DataFrames.\n",
        "4. **Loss Plotting**: The loss for both models is plotted on the same graph for comparison and saved as a JPEG file."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9e5cc5d1"
      },
      "source": [
        "bow_ff_nn_predictions_dropout = []\n",
        "original_lables_ff_bow_dropout = []\n",
        "\n",
        "ff_nn_bow_model_dropout.eval() # Set model to evaluation mode\n",
        "with torch.no_grad():\n",
        "    for index, row in X_test.iterrows():\n",
        "        bow_vec = make_bow_vector(review_dict, row['stemmed_tokens'])\n",
        "        probs = ff_nn_bow_model_dropout(bow_vec)\n",
        "        bow_ff_nn_predictions_dropout.append(torch.argmax(probs, dim=1).cpu().numpy()[0])\n",
        "        original_lables_ff_bow_dropout.append(make_target(Y_test['sentiment'][index]).cpu().numpy()[0])\n",
        "\n",
        "print(\"Classification Report with Dropout:\")\n",
        "print(classification_report(original_lables_ff_bow_dropout, bow_ff_nn_predictions_dropout))\n",
        "\n",
        "ffnn_loss_df = pd.read_csv(ffnn_loss_file_name)\n",
        "ffnn_loss_df_dropout = pd.read_csv(ffnn_loss_file_name_dropout)\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(ffnn_loss_df['iter'], ffnn_loss_df[' loss'], label='Without Dropout')\n",
        "plt.plot(ffnn_loss_df_dropout['iter'], ffnn_loss_df_dropout[' loss'], label='With Dropout')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Training Loss with and Without Dropout')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.savefig(\"ffnn_bow_loss_comparison_dropout.jpg\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}